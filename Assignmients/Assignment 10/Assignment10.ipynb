{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10, Machine Learning Summer Term 2017, Uni Freiburg \n",
    "\n",
    "------------------------------\n",
    "As a reminder of our syntax during the assignment, you will see __Tasks__ and __Questions__.\n",
    "\n",
    "__Tasks__ are the steps you should follow to find to the solution. Nothing has to be reported for them.\n",
    "\n",
    "__Questions __ In this assignment you do not need to upload your answers to the wiki. Instead, you can upload your completed ipython notebooks to your git repository. You will receive personal feedback upon your submissions by the tutors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10.1: Pen & Paper: Backpropagation\n",
    "\n",
    "In the first exercise you will calculate the gradients for a different feed-forward architecture with traditional methods in [10.1 Pen & Paper: Backpropagation](10.1 Pen and Paper Backpropagation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10.2: Implementing Backpropagation\n",
    "\n",
    "This exercise helps you to implement a multi-layer perceptron as described in the lecture and use it on the Boston Housing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10.3: Neural Network Playground\n",
    "\n",
    "To get a feel what neural networks can do and what differences all the options make, Daniel Smilkov and Shan Carter have implemented a great web visualization tool for Google's TensorFlow library: [Neural Network Playground](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.15251&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q 10.3.1: What does the decision boundary for a classification problem look like if you use 3 hidden layers with linear activations? You can set the option to discretize the output, if the probabilistic version is hard to judge. Will more layers help?**\n",
    "\n",
    "**Q 10.3.2: Set up a network with 6 hidden layers, 4 units each and learning rate of 0.3. Compare the training of sigmoid and rectified linear activations. What happens? Can you think of an explanation?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
